# -*- coding: utf-8 -*-
"""Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SGl7nwLvVRWwaJEdYScGqUgOO7OCTXmi
"""

# Import necessary libraries
import pandas as pd

# Path to the files on Google Drive
test_csv_path = 'test.csv'
test_label_csv_path = 'test_label.csv'
train_csv_path = 'train.csv'

# Load the data into pandas DataFrames
test_df = pd.read_csv(test_csv_path)
test_label_df = pd.read_csv(test_label_csv_path)
train_df = pd.read_csv(train_csv_path)

# Display the first few rows of each DataFrame to verify the loading
print("Test Data:")
print(test_df.head())
print("\nTest Label Data:")
print(test_label_df.head())
print("\nTrain Data:")
print(train_df.head())

from sklearn.preprocessing import StandardScaler

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit on training data and transform both train and test data
train_scaled = scaler.fit_transform(train_df)
test_scaled = scaler.transform(test_df)

# Convert back to DataFrame for easier handling later
train_df_scaled = pd.DataFrame(train_scaled, columns=train_df.columns)
test_df_scaled = pd.DataFrame(test_scaled, columns=test_df.columns)

import matplotlib.pyplot as plt
print("Training data loaded with shape:", train_df.shape)  # Data loading and shape check

# Select numerical columns
numerical_columns = train_df.select_dtypes(include=['int64', 'float64']).columns

# Plot histograms for each numerical variable
for column in numerical_columns:
    plt.figure(figsize=(8, 6))
    sns.histplot(data=train_df, x=column, kde=True)
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

import numpy as np

def apply_geometric_mask(data, mask_rate=0.1):
    # Create a mask with the same shape as the data
    mask = np.random.geometric(p=mask_rate, size=data.shape) > 1  # p > 1 will invert the masking
    return np.multiply(data, mask)

# Example of applying the mask to the scaled train data
train_df_masked = apply_geometric_mask(train_df_scaled.values, mask_rate=0.1)
print(train_df_masked[:5])  # Show the first 5 masked data entries

"""# **Transformer Encoder**"""

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout

def transformer_encoder(inputs, num_heads, ff_dim, rate=0.1):
    # Attention and Normalization
    attention = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)
    attention = Dropout(rate)(attention)
    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)

    # Feed Forward
    outputs = Dense(ff_dim, activation='relu')(attention)
    outputs = Dense(inputs.shape[-1])(outputs)
    outputs = Dropout(rate)(outputs)
    outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)
    return outputs

def build_autoencoder(time_steps, features, num_heads=4, ff_dim=256):
    inputs = Input(shape=(time_steps, features))
    encoded = transformer_encoder(inputs, num_heads, ff_dim)

    # Decoder structure can mirror the encoder or be a simple MLP
    decoded = Dense(features, activation='sigmoid')(encoded)

    # Complete the model
    autoencoder = Model(inputs, decoded)
    autoencoder.compile(optimizer='adam', loss='mse')
    return autoencoder

# Parameters
time_steps = train_df_scaled.shape[1]  # Number of features as timestep if using single timestep per feature
features = 1  # Number of parallel series (1 if univariate)

# Build the model
autoencoder = build_autoencoder(time_steps, features)
print(autoencoder.summary())

"""# Convert to TensorFlow dataset for easier shuffling, batching, etc.
train_dataset = tf.data.Dataset.from_tensor_slices((train_df_masked, train_df_scaled.values))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)

# Train the autoencoder
epochs = 10  # You can adjust the number of epochs based on your specific requirements
autoencoder.fit(train_dataset, epochs=epochs)
"""



import numpy as np
import pandas as pd
import tensorflow as tf
import time
from tensorflow.keras.layers import Input, Dense, BatchNormalization, Lambda, Concatenate, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
from tensorflow.keras.callbacks import LearningRateScheduler
import tensorflow.keras.backend as K
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense


# Function to compute anomaly score
def anomaly_score(data):
    reconstruction = autoencoder.predict(data)  # Corrected to pass single dataset
    error = np.mean(np.abs(data - reconstruction), axis=1)  # Anomaly score calculation
    return error
# Define a learning rate decay function
def scheduler(epoch, lr):
    if epoch < 10:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

lr_schedule = LearningRateScheduler(scheduler)
# Constants
NUM_FEATURES = train_data.shape[1]  # Number of features
BATCH_SIZE = 64  # Batch size
EPOCHS = 5  # Number of epochs
LEARNING_RATE = 0.0005  # Learning rate

# Define contrastive loss function
def contrastive_loss(y_true, y_pred, margin=1):
    square_pred = tf.square(y_pred)
    margin_square = tf.square(tf.maximum(margin - y_pred, 0))
    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)

# Adding Dropout in the model
def build_autoencoder(input_shape):
    inputs = Input(shape=(input_shape,))
    x = Dense(64, activation='relu')(inputs)
    x = Dropout(0.2)(x)  # Dropout added
    x = Dense(32, activation='relu')(x)
    x = Dropout(0.2)(x)  # Dropout added
    decoded = Dense(input_shape, activation='sigmoid')(x)
    autoencoder = Model(inputs, decoded)
    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
    return autoencoder

# Build generator
def build_generator():
    inputs = Input(shape=(NUM_FEATURES,))
    x = Dense(64, activation='relu')(inputs)
    x = Dense(32, activation='relu')(x)
    decoded = Dense(NUM_FEATURES, activation='sigmoid')(x)
    generator = Model(inputs, decoded)
    return generator

def build_discriminator(input_shape):
    inputs = Input(shape=(input_shape,))
    x = Dense(64, activation='relu')(inputs)
    x = Dense(32, activation='relu')(x)
    outputs = Dense(1, activation='sigmoid')(x)
    discriminator = Model(inputs, outputs)
    discriminator.compile(optimizer='adam', loss='binary_crossentropy')
    return discriminator

# Build the discriminator with the correct input shape
input_shape = reconstructions.shape[1]  # Assuming reconstructions have been squeezed correctly
discriminator = build_discriminator(input_shape)


# GAN Model
class GAN(Model):
    def __init__(self, autoencoder, discriminator):
        super(GAN, self).__init__()
        self.autoencoder = autoencoder
        self.discriminator = discriminator

    def compile(self, ae_optimizer, d_optimizer, loss_fn):
        super(GAN, self).compile()
        self.ae_optimizer = ae_optimizer
        self.d_optimizer = d_optimizer
        self.loss_fn = loss_fn

    def train_step(self, data):
        real_data, _ = data

        # Autoencoder training
        with tf.GradientTape() as ae_tape:
            reconstructed = self.autoencoder(real_data)
            ae_loss = self.loss_fn(real_data, reconstructed)

        # Train the autoencoder
        ae_grads = ae_tape.gradient(ae_loss, self.autoencoder.trainable_weights)
        self.ae_optimizer.apply_gradients(zip(ae_grads, self.autoencoder.trainable_weights))

        # Discriminator training
        with tf.GradientTape() as d_tape:
            real_output = self.discriminator(real_data)
            fake_output = self.discriminator(reconstructed)
            d_loss = self.loss_fn(tf.ones_like(real_output), real_output) + self.loss_fn(tf.zeros_like(fake_output), fake_output)

        # Train the discriminator
        d_grads = d_tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_weights))

        return {"ae_loss": ae_loss, "d_loss": d_loss}

# Compile and train the GAN
gan = GAN(autoencoder, discriminator)
gan.compile(
    ae_optimizer=tf.keras.optimizers.Adam(),
    d_optimizer=tf.keras.optimizers.Adam(),
    loss_fn=tf.keras.losses.BinaryCrossentropy()
)

# Train the GAN
gan.fit(train_dataset, epochs=epochs)

end_time = time.time()
training_time = end_time - start_time
# Check for any NaN values in training history
if np.isnan(history.history['loss']).any():
    print("Training failed with NaN values in loss.")
else:
    print("Training completed without NaN values.")

# Compute reconstruction errors for test data
test_scores = anomaly_score(test_data)

# Compute AUC Score
auc_score = roc_auc_score(test_label_df['label'], test_scores)

# Print AUC Score
print("AUC Score:", auc_score)

# Determine a threshold for anomaly detection
threshold = np.percentile(test_scores, 95)  # Threshold determination
anomalies = test_df[test_scores > threshold]  # Anomaly detection


# Print detected anomalies
print("Detected anomalies:")
print(anomalies)

# Plot losses
import matplotlib.pyplot as plt
plt.plot(history.history['loss'])
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()

# Compute precision, recall, and F1-score
precision = precision_score(test_label_df['label'], test_scores > threshold)
recall = recall_score(test_label_df['label'], test_scores > threshold)
f1 = f1_score(test_label_df['label'], test_scores > threshold)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Time taken for training:", training_time, "seconds")

import matplotlib.pyplot as plt
# Plot each feature over time
plt.figure(figsize=(12, 8))
for feature in detected_anomalies.keys():
    if feature != 'timestamp_(min)':
        plt.plot(detected_anomalies['timestamp_(min)'], detected_anomalies[feature], label=feature)
plt.xlabel('Timestamp (min)')
plt.ylabel('Feature Value')
plt.title('Detected Anomalies')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Define the values
precision = 0.8176229508196722
recall = 0.14728682170542637
f1_score = 0.24960900844541759
auc_score = 0.7947394073542022

# Create lists for the values and corresponding labels
values = [precision, recall, f1_score, auc_score]
labels = ['Precision', 'Recall', 'F1-score', 'AUC Score']

# Create a bar plot
plt.figure(figsize=(8, 6))
plt.bar(labels, values, color=['blue', 'green', 'orange', 'red'])
plt.xlabel('Metrics')
plt.ylabel('Values')
plt.title('Performance Metrics')
plt.ylim(0, 1)  # Set y-axis limit to ensure all values are visible
plt.grid(axis='y')
plt.show()